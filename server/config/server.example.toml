# LSDAMM Coordination Server Configuration
# Copy this file to server.toml and fill in your values

[server]
host = "0.0.0.0"
port = 3001
cors_origins = ["https://claude.ai", "https://chat.openai.com"]

[database]
path = "./data/mesh.db"

[logging]
level = "info"   # debug, info, warn, error
path = "./logs"

[auth]
jwt_secret = "CHANGE_THIS_TO_A_SECURE_RANDOM_STRING"
jwt_expires_in = "24h"
session_timeout_ms = 3600000  # 1 hour

[rate_limit]
window_ms = 60000   # 1 minute
max_requests = 100

[websocket]
heartbeat_interval_ms = 30000
heartbeat_timeout_ms = 90000

[providers]
# OpenAI Configuration
[providers.openai]
enabled = true
api_key = ""
organization_id = ""
default_model = "gpt-4o"

# Anthropic Configuration
[providers.anthropic]
enabled = true
api_key = ""
default_model = "claude-opus-4-5-20251101"

# Google Gemini Configuration
[providers.google]
enabled = false
api_key = ""
default_model = "gemini-3-pro"

# xAI Grok Configuration
[providers.xai]
enabled = false
api_key = ""
default_model = "grok-4-1-fast-reasoning"

# Ollama Local Configuration
[providers.ollama_local]
enabled = true
base_url = "http://localhost:11434"
default_model = "llama3.1"

# Ollama Cloud Configuration
[providers.ollama_cloud]
enabled = false
base_url = "https://ollama.com"
api_key = ""
default_model = "llama3.1"

[memory]
# Vector database (qdrant or weaviate)
vector_db = "qdrant"
vector_db_url = "http://localhost:6333"

# Search engine (meilisearch or elasticsearch)
search_engine = "meilisearch"
search_engine_url = "http://localhost:7700"
search_engine_key = ""

# Embedding model
embedding_model = "text-embedding-3-large"
embedding_provider = "openai"

[monitoring]
prometheus_enabled = true
metrics_path = "/metrics"
